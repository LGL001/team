import streamlit as st
import pandas as pd
import joblib
import re
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# -----------------------------------------------------------------------------
# 1. ì„¤ì • ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (ëª¨ë¸ í•™ìŠµë•Œë‘ ë˜‘ê°™ì•„ì•¼ í•¨!)
# -----------------------------------------------------------------------------

# ë¶ˆìš©ì–´ ì²˜ë¦¬ëŠ” ê¸€ì ë‹¨ìœ„ë¼ í¬ê²Œ ì¤‘ìš”í•˜ì§„ ì•Šì§€ë§Œ í˜•íƒœëŠ” ìœ ì§€
def custom_preprocessor(text):
    text = re.sub(r'\d+', ' ', text)  # ìˆ«ì ì œê±°
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'\s+', ' ', text)  # ê³µë°± ì •ë¦¬
    return text


# Streamlitì€ ì†ë„ë¥¼ ìœ„í•´ ìºì‹±(@st.cache_resource)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
@st.cache_resource
def load_prediction_model():
    """í•™ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ"""
    try:
        model = joblib.load('major_predictor_model.pkl')
        vec = joblib.load('major_vectorizer.pkl')
        return model, vec
    except Exception as e:
        return None, None


@st.cache_resource
def load_recommendation_engine():
    """ì¶”ì²œ ì‹œìŠ¤í…œ ë°ì´í„° ë° ë²¡í„° ë¡œë“œ (ì‹œê°„ì´ ì¢€ ê±¸ë¦¬ë‹ˆ ìºì‹± í•„ìˆ˜)"""
    try:
        df = pd.read_csv("dataset_v2.csv")
        # IT ê³„ì—´ ë°ì´í„°ë§Œ ì‚¬ìš© (ì¡±ë³´)
        it_df = df[df['category'] == 'IT_Engineering']

        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìª¼ê°œê¸°
        sentences = []
        for text in it_df['text']:
            # ë¬¸ì¥ ë¶„ë¦¬ (. ë˜ëŠ” ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            splits = re.split(r'[.|\n]', str(text))
            for s in splits:
                s = s.strip()
                if len(s) > 15:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ì€ ì œì™¸
                    sentences.append(s)

        # ì¶”ì²œìš© ë²¡í„°í™” (ê¸€ì ë‹¨ìœ„)
        vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))
        tfidf_matrix = vectorizer.fit_transform(sentences)

        return sentences, vectorizer, tfidf_matrix
    except Exception as e:
        return [], None, None


# -----------------------------------------------------------------------------
# 2. UI êµ¬ì„± (ì—¬ê¸°ê°€ ì›¹ì‚¬ì´íŠ¸ í™”ë©´ ë§Œë“œëŠ” ê³³)
# -----------------------------------------------------------------------------

st.set_page_config(page_title="ìƒëª…ëŒ€ AI ì…ì‹œ ì»¨ì„¤í„´íŠ¸", page_icon="ğŸ“", layout="wide")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ“ AI ì…ì‹œ ì»¨ì„¤í„´íŠ¸")
st.sidebar.info("ìƒëª…ëŒ€í•™êµ ì‹¤ì œ í•©ê²©ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
menu = st.sidebar.radio("ë©”ë‰´ ì„ íƒ", ["í™ˆ(Home)", "IT ì í•©ë„ ì§„ë‹¨", "ì„¸íŠ¹ ë¬¸ì¥ ì¶”ì²œê¸°"])

# ëª¨ë¸ ë¡œë”©
pred_model, pred_vec = load_prediction_model()
rec_sentences, rec_vec, rec_matrix = load_recommendation_engine()

# --- [ë©”ë‰´ 1] í™ˆ ---
if menu == "í™ˆ(Home)":
    st.title("ğŸ“ ìƒëª…ëŒ€ ìƒê¸°ë¶€ AI ë¶„ì„ ì†”ë£¨ì…˜")
    st.markdown("""
    ### í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‘‹
    ì´ ì„œë¹„ìŠ¤ëŠ” **ìì—°ì–´ ì²˜ë¦¬(NLP)** ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ë¶„ì˜ ìƒí™œê¸°ë¡ë¶€ë¥¼ ë¶„ì„í•´ì¤ë‹ˆë‹¤.

    #### ğŸ” ì£¼ìš” ê¸°ëŠ¥
    1. **IT ì í•©ë„ ì§„ë‹¨**: ë‚´ê°€ ì“´ ì„¸íŠ¹ì´ ì»´í“¨í„°ê³¼í•™ê³¼/ITê³„ì—´ì— ì–¼ë§ˆë‚˜ ì í•©í•œì§€ ì ìˆ˜ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
    2. **ì„¸íŠ¹ ë¬¸ì¥ ì¶”ì²œ**: ë‚´ í™œë™ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´, **ì‹¤ì œ í•©ê²©ìƒ ì„ ë°°ë“¤ì˜ ëª…ë¬¸ì¥**ì„ ì°¾ì•„ì¤ë‹ˆë‹¤.

    ---
    *Developed by Computer Science Dept. Student*
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.success(f"ğŸ“š í•™ìŠµëœ ë°ì´í„°: **{len(rec_sentences)}ê°œ**ì˜ ë¬¸ì¥")
    with col2:
        st.info("ğŸ¤– ì ìš©ëœ AI ëª¨ë¸: **Logistic Regression & TF-IDF (Char-level)**")

# --- [ë©”ë‰´ 2] IT ì í•©ë„ ì§„ë‹¨ ---
elif menu == "IT ì í•©ë„ ì§„ë‹¨":
    st.header("ğŸ’» IT/ì»´í“¨í„°ê³µí•™ ì í•©ë„ ì§„ë‹¨")
    st.write("ì‘ì„±í•˜ì‹  ì„¸íŠ¹ ë‚´ìš©ì´ë‚˜ ìê¸°ì†Œê°œì„œ ì´ˆì•ˆì„ ì…ë ¥í•´ë³´ì„¸ìš”.")

    if pred_model is None:
        st.error("ğŸš¨ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! (major_predictor_model.pkl)")
    else:
        user_input = st.text_area("ë‚´ìš© ì…ë ¥", height=200, placeholder="ì˜ˆ: íŒŒì´ì¬ì„ í™œìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•¨...")

        if st.button("ì§„ë‹¨í•˜ê¸°"):
            if len(user_input) < 10:
                st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ì˜ˆì¸¡
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    vec_input = pred_vec.transform([user_input])
                    prob = pred_model.predict_proba(vec_input)[0]
                    score = prob[1] * 100  # IT í™•ë¥ 

                # ê²°ê³¼ ì‹œê°í™”
                st.divider()
                st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")

                # ê²Œì´ì§€ ë°”
                st.progress(int(score))
                st.metric(label="IT ê³„ì—´ ì í•©ë„", value=f"{score:.1f}ì ")

                if score >= 85:
                    st.success("ğŸ† **[í•©ê²©ê¶Œ]** ì™„ë²½í•©ë‹ˆë‹¤! ì „ê³µ ê´€ë ¨ í‚¤ì›Œë“œê°€ í’ë¶€í•©ë‹ˆë‹¤.")
                    st.balloons()
                elif score >= 60:
                    st.info("âœ¨ **[ìš°ìˆ˜]** ì¢‹ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ê¸°ìˆ  ìš©ì–´ë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”.")
                else:
                    st.warning("ğŸ¤” **[ë…¸ë ¥ í•„ìš”]** IT ê´€ë ¨ ì „ë¬¸ ìš©ì–´(ì•Œê³ ë¦¬ì¦˜, ì–¸ì–´ ì´ë¦„ ë“±)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# --- [ë©”ë‰´ 3] ì„¸íŠ¹ ë¬¸ì¥ ì¶”ì²œê¸° ---
elif menu == "ì„¸íŠ¹ ë¬¸ì¥ ì¶”ì²œê¸°":
    st.header("ğŸ“ í•©ê²©ìƒ ì¡±ë³´(ì„¸íŠ¹) ì¶”ì²œê¸°")
    st.write("í™œë™ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´, ì„ ë°°ë“¤ì´ ì‹¤ì œë¡œ ì¼ë˜ **í•©ê²© ë¬¸ì¥**ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.")

    if len(rec_sentences) == 0:
        st.error("ğŸš¨ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨ (dataset_v2.csv í™•ì¸ í•„ìš”)")
    else:
        keyword = st.text_input("í™œë™ í‚¤ì›Œë“œ ì…ë ¥", placeholder="ì˜ˆ: ê²Œì„ ì œì‘, ë°ì´í„° ë¶„ì„, ë™ì•„ë¦¬ í™œë™")

        if st.button("í•©ê²© ë¬¸ì¥ ê²€ìƒ‰"):
            with st.spinner("ì„ ë°°ë“¤ì˜ ìƒê¸°ë¶€ë¥¼ ë’¤ì§€ëŠ” ì¤‘..."):
                # ê²€ìƒ‰ ë¡œì§
                query_vec = rec_vec.transform([keyword])
                similarities = cosine_similarity(query_vec, rec_matrix).flatten()

                # Top 3 ì¶”ì¶œ
                top_indices = similarities.argsort()[-5:][::-1]  # 5ê°œ ë½‘ìŒ

                st.divider()
                st.subheader(f"ğŸ” '{keyword}' ê´€ë ¨ ì¶”ì²œ ë¬¸ì¥")

                count = 0
                for idx in top_indices:
                    sim_score = similarities[idx]
                    if sim_score > 0.15:  # ìœ ì‚¬ë„ 15% ì´ìƒë§Œ í‘œì‹œ
                        count += 1
                        rec_text = rec_sentences[idx]

                        # OCR ì˜¤íƒ€ ì•ˆë‚´
                        st.markdown(f"""
                        > **ì¶”ì²œ {count}** (ìœ ì‚¬ë„ {sim_score * 100:.1f}%)  
                        > " {rec_text} "
                        """)

                if count == 0:
                    st.warning("ë¹„ìŠ·í•œ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë‹¤ë¥´ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”.")