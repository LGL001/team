import pandas as pd
import joblib
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 1. ë°ì´í„° ë¡œë“œ
df = pd.read_csv("dataset_v2.csv")

# 2. ë¼ë²¨ë§ (IT=1, Non-IT=0)
df['label'] = df['category'].apply(lambda x: 1 if x == 'IT_Engineering' else 0)
X = df['text']
y = df['label']

print(f"ğŸ“Š ë°ì´í„° êµ¬ì„±: IT({sum(y==1)}ê°œ) vs ë¹„IT({sum(y==0)}ê°œ)")

# --- [ì „ì²˜ë¦¬ í•¨ìˆ˜] ---
# ë¶ˆìš©ì–´(Stopwords)ëŠ” ê¸€ì ë‹¨ìœ„ í•™ìŠµì—ì„œëŠ” í° ì˜ë¯¸ê°€ ì—†ì–´ì„œ ì œê±° ë¡œì§ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
def custom_preprocessor(text):
    """ìµœì†Œí•œì˜ ë…¸ì´ì¦ˆë§Œ ì œê±°"""
    # 1. ìˆ«ì ì œê±° (ì—°ë„ ë“± ë…¸ì´ì¦ˆ ë°©ì§€)
    text = re.sub(r'\d+', ' ', text)
    # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì , ì‰¼í‘œ ë“±)
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    # 3. ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì„
    text = re.sub(r'\s+', ' ', text)
    return text

# --- [í•µì‹¬ ë³€ê²½: ê¸€ì ë‹¨ìœ„ ë¶„ì„ê¸°] ---
# analyzer='char_wb': ë‹¨ì–´ ê²½ê³„ ì•ˆì—ì„œ ê¸€ì íŒ¨í„´ì„ ì°¾ìŒ
# ngram_range=(2, 4): 2ê¸€ì~4ê¸€ì ë©ì–´ë¦¬ë¥¼ í•™ìŠµ (ì˜ˆ: 'ì»´í“¨', 'í“¨í„°', 'í”„ë¡œê·¸', 'ë˜ë§')
vectorizer = TfidfVectorizer(
    preprocessor=custom_preprocessor,
    analyzer='char_wb',
    ngram_range=(2, 4),
    min_df=1,            # í•œ ë²ˆì´ë¼ë„ ë‚˜ì˜¤ë©´ ë¬´ì¡°ê±´ í•™ìŠµ
    max_features=10000   # íŒ¨í„´ì„ ë„‰ë„‰í•˜ê²Œ 10000ê°œê¹Œì§€ ê¸°ì–µ
)

print("âš™ï¸ í…ìŠ¤íŠ¸ë¥¼ ê¸€ì ì¡°ê°(Character N-grams)ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
X_vec = vectorizer.fit_transform(X)

# 3. ëª¨ë¸ í•™ìŠµ (ê°•ë ¥í•œ ê·œì œ ì ìš©)
model = LogisticRegression(class_weight='balanced', C=10.0, random_state=42, max_iter=2000)
model.fit(X_vec, y)

# ì €ì¥
joblib.dump(model, 'major_predictor_model.pkl')
joblib.dump(vectorizer, 'major_vectorizer.pkl')

print("-" * 30)
print("âœ… ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ! (ì˜¤íƒ€ê°€ ìˆì–´ë„ ë¬¸ë§¥ì„ íŒŒì•…í•©ë‹ˆë‹¤)")

# --- [ê²€ì¦: ì´ì œ ì˜¤íƒ€ë„ ì¸ì‹í•˜ëŠ”ì§€ í™•ì¸] ---
# ì´ì œëŠ” ë‹¨ì–´ê°€ ì•„ë‹ˆë¼ 'íŒ¨í„´'ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
vocab = vectorizer.vocabulary_
test_patterns = ['íŒŒì´', 'ì´ì¬', 'Py', 'yt', 'th', 'ho', 'on', 'ê·¸ë˜', 'ë˜ë§', 'POT']

print("\nğŸ” [ê¸€ì ì¡°ê° ì¸ì‹ í…ŒìŠ¤íŠ¸]")
for pattern in test_patterns:
    if pattern in vocab:
        print(f"ğŸ†— '{pattern}' -> íŒ¨í„´ í•™ìŠµë¨!")
    else:
        print(f"âŒ '{pattern}' -> ì—†ìŒ")

# --- [ì–´ë–¤ íŒ¨í„´ì´ IT ì ìˆ˜ë¥¼ ì˜¬ë ¸ì„ê¹Œ?] ---
coefficients = model.coef_[0]
feature_names = vectorizer.get_feature_names_out()
sorted_idx = coefficients.argsort()

print("\nğŸ”‘ [IT í•©ê²© í•µì‹¬ ê¸€ì íŒ¨í„´ TOP 20]")
# ê¸€ì ë‹¨ìœ„ë¼ ê²°ê³¼ê°€ 'ì»´í“¨', 'í“¨í„°' ì²˜ëŸ¼ ë³´ì¼ ê²ë‹ˆë‹¤. ì´ê²Œ ì •ìƒì…ë‹ˆë‹¤!
top_keywords = [feature_names[i] for i in sorted_idx[-20:]]
print(top_keywords)